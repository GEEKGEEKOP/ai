{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GEEKGEEKOP/ai/blob/main/Test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python file.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mDNpIYdQ-DY7",
        "outputId": "1beb47b8-0242-4757-d55f-12e20004431e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-02-25 18:09:26.096927: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2025-02-25 18:09:26.117040: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2025-02-25 18:09:26.123086: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-02-25 18:09:26.137317: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2025-02-25 18:09:27.436568: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/data/datasets/language_modeling.py:53: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/language-modeling/run_mlm.py\n",
            "  warnings.warn(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice: 3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You chose \"Don't visualize my results\"\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.4\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n",
            "{'train_runtime': 43.1343, 'train_samples_per_second': 4.034, 'train_steps_per_second': 2.017, 'train_loss': 1.5885062382139008, 'epoch': 3.0}\n",
            "100% 87/87 [00:37<00:00,  2.29it/s]\n",
            "Ø³Ù„Ø§Ù…\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Ø³Ù„Ø§Ù… Ø¨Ø´Ø±Ø¯ Ø¨Ø´Ø±Ø¯ Ø¨Ø´Ø±Ø¯ Ø¨Ø´Ø±Ø¯ Ø¨Ø´Ø±Ø¯ Ø¨Ø´Ø±Ø¯ Ø¨Ø´Ø±Ø¯ Ø¨Ø´Ø±Ø¯ Ø¨Ø´Ø±Ø¯ Ø¨Ø´Ø±Ø¯ Ø¨Ø´Ø±Ø¯ Ø¨Ø´Ø±Ø¯ Ø¨Ø´Ø±Ø¯ Ø¨Ø´Ø±Ø¯ Ø¨Ø´Ø±Ø¯ Ø¨Ø´Ø±Ø¯\n",
            "------------------------------------\n",
            "Ø®ÙˆØ¨ÛŒØŸ\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Ø®ÙˆØ¨ÛŒØŸ\n",
            "ð“›ð“žð“ð“”ð“›ð“¨ ð“‘ð“žð“¨ Ù‡ÙÚ˜Ú˜Ù„Ú˜: Ø¨Ø§ Ø¨Ø§ Ø¨Ø§ Ø¨Ø§ Ø¨Ø§ Ø¨Ø§ Ø¨Ø§ Ø¨Ø§ Ø¨Ø§ Ø¨Ø§ Ø¨Ø§ Ø¨Ø§ Ø¨Ø§ Ø¨Ø§ Ø¨Ø§ Ø¨Ø§ Ø¨Ø§\n",
            "------------------------------------\n",
            "Ù¾Ø§ÛŒØªÙˆÙ†\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Ù¾Ø§ÛŒØªÙˆÙ† Ø¨Ø´Ø±Ø´ Ø¨Ø´Ø±Ø´ Ø¨Ø´Ø±Ø´ Ø¨Ø´Ø±Ø´ Ø¨Ø´Ø±Ø´ Ø¨Ø´Ø±Ø´ Ø¨Ø´Ø±Ø´ Ø¨Ø´Ø±Ø´ Ø¨Ø´Ø±Ø´ Ø¨Ø´Ø±Ø´ Ø¨Ø´Ø±Ø´ Ø¨Ø´Ø±Ø´ Ø¨Ø´Ø±Ø´ ï¿½\n",
            "------------------------------------\n",
            "Ù¾Ø§Ø±Ø³Ø§\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Ù¾Ø§Ø±Ø³Ø§Ù† Ø¨Ø´Ø±Ø²ÛŒÙ† Ø¨Ø´Ø±Ø²ÛŒÙ† Ø¨Ø´Ø±Ø²ÛŒÙ† Ø¨Ø´Ø±Ø²ÛŒÙ† Ø¨Ø´Ø±Ø²ÛŒÙ† Ø¨Ø´Ø±Ø²ÛŒÙ† Ø¨Ø´Ø±Ø²ÛŒÙ† Ø¨Ø´Ø±Ø²ÛŒÙ† Ø¨Ø´Ø±Ø²ÛŒÙ† Ø¨ï¿½\n",
            "------------------------------------\n",
            "Ø¬Ù†Ø¯Ù‡\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Ø¬Ù†Ø¯Ù‡ Ø¨Ø®ÙˆØ¯ Ø¨Ø®ÙˆØ¯ Ø¨Ø®ÙˆØ¯ Ø¨Ø®ÙˆØ¯ Ø¨Ø®ÙˆØ¯ Ø¨Ø®ÙˆØ¯ Ø¨Ø®ÙˆØ¯ Ø¨Ø®ÙˆØ¯ Ø¨Ø®ÙˆØ¯ Ø¨Ø®ÙˆØ¯ Ø¨Ø®ÙˆØ¯ Ø¨Ø®ÙˆØ¯ Ø¨Ø®ÙˆØ¯ Ø¨Ø®ÙˆØ¯ Ø¨Ø®ÙˆØ¯ Ø¨Ø®Ùˆ\n",
            "------------------------------------\n",
            "Ù¾Ú¯Ø§Ù‡\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Ù¾Ú¯Ø§Ù‡ Ø¨Ø´ÛŒØ¯ Ø¨Ø´ÛŒØ¯ Ø¨Ø´ÛŒØ¯ Ø¨Ø´ÛŒØ¯ Ø¨Ø´ÛŒØ¯ Ø¨Ø´ÛŒØ¯ Ø¨Ø´ÛŒØ¯ Ø¨Ø´ÛŒØ¯ Ø¨Ø´ÛŒØ¯ Ø¨Ø´ÛŒØ¯ Ø¨Ø´ÛŒØ¯ Ø¨Ø´ÛŒØ¯ Ø¨Ø´ÛŒØ¯ Ø¨ï¿½\n",
            "------------------------------------\n",
            "Ú†Ø±Ø§ ØªÚ©Ø±Ø§Ø± Ù…ÛŒÚ©Ù†ÛŒ \n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Ú†Ø±Ø§ ØªÚ©Ø±Ø§Ø± Ù…ÛŒÚ©Ù†ÛŒ Ú©Ø±Ø§Ø± Ø¨Ø´Ø±Ø§Ù† Ø¨Ø´Ø±Ø§Ù† Ø¨Ø´Ø±Ø§Ù† Ø¨Ø´Ø±Ø§Ù† Ø¨Ø´Ø±Ø§Ù† Ø¨Ø´Ø±Ø§Ù† Ø¨Ø´Ø±Ø§Ù† Ø¨Ø´Ø±Ø§Ù† Ø¨Ø´Ø±Ø§Ù† Ø¨Ø´Ø±Ø§Ù† Ø¨Ø´Ø±\n",
            "------------------------------------\n",
            "Ø¨Ø®ÙˆØ±\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Ø¨Ø®ÙˆØ± Ø¨Ø®ÙˆØ± Ø¨Ø®ÙˆØ± Ø¨Ø®ÙˆØ± Ø¨Ø®ÙˆØ± Ø¨Ø®ÙˆØ± Ø¨Ø®ÙˆØ± Ø¨Ø®ÙˆØ± Ø¨Ø®ÙˆØ± Ø¨Ø®ÙˆØ± Ø¨Ø®ÙˆØ± Ø¨Ø®ÙˆØ± Ø¨Ø®ÙˆØ± Ø¨Ø®ÙˆØ± Ø¨Ø®ÙˆØ± Ø¨Ø®ÙˆØ± Ø¨Ø®Ùˆ\n",
            "------------------------------------\n",
            "Ø¨Ú¯Ùˆ\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Ø¨Ú¯ÙˆÙ† Ø¨Ø´Ø±ÛŒØ²\n",
            "ð“›ð“žð“ð“”ð“›ð“¨ ð“‘ð“žð“¨ Ù‡ÙÚ˜Ú˜Ù„Ú˜: Ø¨Ø´Ø±ÛŒØ²\n",
            "ð“›ð“žð“ð“”ð“›ð“¨ ð“‘ð“žð“¨ Ù‡ÙÚ˜ï¿½\n",
            "------------------------------------\n",
            "parsa\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "parsa: ð•½ð–†ð–ð–Žð–’: ð•½ð–†ð–ð–Žð–’: ð•½ð–†ð–ð–Žð–’: ð•½ð–†ð–ð–Žð–’: ð•½ð–†ð–ð–Žð–’: ð•½ð–†ð–ï¿½\n",
            "------------------------------------\n",
            "Ø¯Ø±ÙˆØ¯\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Ø¯Ø±ÙˆØ¯ Ø¨Ø´Ø±ÙˆØ¯ Ø¨Ø´Ø±ÙˆØ¯ Ø¨Ø´Ø±ÙˆØ¯ Ø¨Ø´Ø±ÙˆØ¯ Ø¨Ø´Ø±ÙˆØ¯ Ø¨Ø´Ø±ÙˆØ¯ Ø¨Ø´Ø±ÙˆØ¯ Ø¨Ø´Ø±ÙˆØ¯ Ø¨Ø´Ø±ÙˆØ¯ Ø¨Ø´Ø±ÙˆØ¯ Ø¨Ø´Ø±ÙˆØ¯ Ø¨Ø´Ø±ÙˆØ¯ Ø¨Ø´Ø±ÙˆØ¯ Ø¨Ø´Ø±\n",
            "------------------------------------\n",
            "Ø¨Ø´Ø±\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Ø¨Ø´Ø± Ø¨Ø´Ø¯ Ø¨Ø´Ø¯ Ø¨Ø´Ø¯ Ø¨Ø´Ø¯ Ø¨Ø´Ø¯ Ø¨Ø´Ø¯ Ø¨Ø´Ø¯ Ø¨Ø´Ø¯ Ø¨Ø´Ø¯ Ø¨Ø´Ø¯ Ø¨Ø´Ø¯ Ø¨Ø´Ø¯ Ø¨Ø´Ø¯ Ø¨Ø´Ø¯ Ø¨Ø´Ø¯ Ø¨Ø´Ø¯ Ø¨Ø´Ø¯ Ø¨Ø´Ø¯ Ø¨Ø´Ø¯ ï¿½\n",
            "------------------------------------\n",
            "Ø´Ø´Ø´Ø´\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Ø´Ø´Ø´Ø´Ø´Ø´Ø´Ø´Ø´Ø´Ø´Ø´Ø´Ø´Ø´Ø´Ø´Ø´Ø´Ø´Ø´Ø´Ø´Ø´Ø´Ø´Ø´Ø´Ø´Ø´Ø´Ø´Ø´Ø´Ø´Ø´Ø´Ø´Ø´Ø´Ø´Ø´Ø´Ø´Ø´Ø´Ø´Ø´Ø´Ø´\n",
            "------------------------------------\n",
            "Ø¹Ø±Ø¨ÛŒ\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Ø¹Ø±Ø¨ÛŒ Ø¨Ø´Ø±ÛŒ Ø¨Ø´Ø±ÛŒ Ø¨Ø´Ø±ÛŒ Ø¨Ø´Ø±ÛŒ Ø¨Ø´Ø±ÛŒ Ø¨Ø´Ø±ÛŒ Ø¨Ø´Ø±ÛŒ Ø¨Ø´Ø±ÛŒ Ø¨Ø´Ø±ÛŒ Ø¨Ø´Ø±ÛŒ Ø¨Ø´Ø±ÛŒ Ø¨Ø´Ø±ÛŒ Ø¨Ø´Ø±ÛŒ Ø¨Ø´\n",
            "------------------------------------\n",
            "66\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "66.\n",
            "\n",
            "The following are some of the most popular and popular posts on the site:\n",
            "\n",
            "1.\n",
            "\n",
            "2.\n",
            "\n",
            "3.\n",
            "\n",
            "4.\n",
            "\n",
            "5.\n",
            "\n",
            "6.\n",
            "\n",
            "7.\n",
            "\n",
            "8.\n",
            "\n",
            "9.\n",
            "\n",
            "10.\n",
            "\n",
            "11.\n",
            "\n",
            "12.\n",
            "\n",
            "13.\n",
            "\n",
            "14.\n",
            "\n",
            "15.\n",
            "\n",
            "16.\n",
            "\n",
            "17.\n",
            "\n",
            "18.\n",
            "\n",
            "19.\n",
            "\n",
            "20.\n",
            "\n",
            "------------------------------------\n",
            "Ø§Ø¨Ùˆ Ø·Ø§Ù„Ø¨ÛŒ\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Ø§Ø¨Ùˆ Ø·Ø§Ù„Ø¨ÛŒØ± Ø¨Ø´Ø±Ø¯ Ø¨Ø´Ø±Ø¯ Ø¨Ø´Ø±Ø¯ Ø¨Ø´Ø±Ø¯ Ø¨Ø´Ø±Ø¯ Ø¨Ø´Ø±Ø¯ Ø¨Ø´Ø±Ø¯ Ø¨Ø´Ø±Ø¯ Ø¨Ø´Ø±Ø¯ Ø¨Ø´Ø±Ø¯ Ø¨Ø´Ø±Ø¯ Ø¨Ø´Ø±Ø¯ Ø¨Ø´Ø±Ø¯ Ø¨Ø´Ø±Ø¯ Ø¨Ø´Ø±Ø¯\n",
            "------------------------------------\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Welcome To Colab",
      "toc_visible": true,
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}